<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>HEBench: Benchmark Configuration File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">HEBench
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('config_file_reference.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Benchmark Configuration File Reference </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><p><a class="anchor" id="md_docsrc_config_file_reference"></a></p>
<p>Benchmark configuration files can be specified during a run of Test Harness via the <code>--benchmark_config_file</code> command line argument.</p>
<p>A configuration file contains a list of benchmarks to run and parameters to use for each workload. While the syntax of configuration files is the same for all, IDs for benchmarks are specific to each backend.</p>
<h1><a class="anchor" id="autotoc_md7"></a>
Configuration file syntax</h1>
<p>A configuration file is a YAML file with the following syntax:</p>
<div class="fragment"><div class="line">default_min_test_time: &lt;fallback_min_test_time_ms&gt;</div>
<div class="line">default_sample_size: &lt;fallback_sample_size&gt;</div>
<div class="line">random_seed: &lt;seed&gt;</div>
<div class="line"> </div>
<div class="line">benchmark:</div>
<div class="line">  - ID: &lt;benchmark_id&gt;</div>
<div class="line">    default_min_test_time: &lt;min_test_time_ms&gt;</div>
<div class="line">    default_sample_sizes:</div>
<div class="line">      0: &lt;sample_size&gt;</div>
<div class="line">      1: &lt;sample_size&gt;</div>
<div class="line">      ...</div>
<div class="line">    params:</div>
<div class="line">      0:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      1:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      ...</div>
<div class="line">  - ID: &lt;benchmark_id&gt;</div>
<div class="line">    default_min_test_time: &lt;min_test_time_ms&gt;</div>
<div class="line">    default_sample_sizes:</div>
<div class="line">      0: &lt;sample_size&gt;</div>
<div class="line">      1: &lt;sample_size&gt;</div>
<div class="line">      ...</div>
<div class="line">    params:</div>
<div class="line">      0:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      1:</div>
<div class="line">        name: &lt;param_name&gt;</div>
<div class="line">        type: &lt;param_type&gt;</div>
<div class="line">        value:</div>
<div class="line">          from: &lt;value_from&gt;</div>
<div class="line">          to: &lt;value_to&gt;</div>
<div class="line">          step: &lt;value_step&gt;</div>
<div class="line">      ...</div>
<div class="line">  ...</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md8"></a>
Benchmark parameters</h2>
<p>The configuration file can have settings for certain default behaviors. These are optional.</p>
<ul>
<li><p class="startli"><code>default_min_test_time</code> - type: <code>uint64</code>. Specifies the default minimum test time in <em>milliseconds</em> for a benchmark.</p>
<p class="startli">For <b>Latency</b> tests that support flexible test times, this is the minimum time for which they will run. As always, regardless of the value specified, all latency tests will run, at least, two iterations. <b>Offline</b> tests will run through the whole dataset, at least, once. If this minimum test time hasn't elapsed by the end of the run, a new run is executed. This behavior continues until the test time elapses.</p>
</li>
<li><p class="startli"><code>default_sample_size</code> - type: <code>uint64</code>. Specifies the number of samples to be used for an operation parameter in <b>Offline</b> tests that support flexible sample size. Inside the benchmark description, this setting specifies the sample size for an operand in the workload operation by index (missing indices, or values of <code>0</code> will cause the configuration to use the global fallback value).</p>
<p class="startli">Offline benchmarks can directly specify the sample size for each operation parameter, or indicate which parameters support flexible sample sizes. All workloads define a default sample size if none is specified for flexible parameters. When this setting is missing or set to <code>0</code>, indicates that these pre-defined workload sample sizes are to be used for flexible parameters.</p>
</li>
<li><code>random_seed</code> - type: <code>uint64</code>. Specifies the seed for the random number generator to use when generating synthetic data. When missing, the global Test Harness seed will be used (see command line <code>--random_seed</code> in <a class="el" href="test_harness_usage_guide.html">Test Harness User Guide</a> ). This value can be used to replicate results during tests.</li>
</ul>
<p><br  />
 The actual value used for a benchmark for <code>default_min_test_time</code> and <code>default_sample_size</code> is based on where it is specified first in the priority list. The priority is:</p>
<ol type="1">
<li>Backend specified.</li>
<li>Benchmark specific in config file.</li>
<li>Global config file.</li>
<li>Workload specification.</li>
<li>Global specification.</li>
</ol>
<p>If any of these is <code>0</code> or is missing, then the next down the list is used. For sample sizes, workload specification must always be greater than <code>0</code> as there is no global default specification for sample sizes.</p>
<h2><a class="anchor" id="autotoc_md9"></a>
Benchmark descriptions</h2>
<p>Top level <code>benchmark</code> key contains a list. It must exist in the configuration file. An element of this list specifies a benchmark to run and its description.</p>
<p>A benchmark description is composed by <code>ID</code>, <code>default_min_test_time</code>, <code>default_sample_sizes</code> and <code>params</code>.</p>
<p>A benchmark executes a specific workload from the set of workloads specified in <a class="el" href="namespacehebench_1_1APIBridge.html#aeb7e1cd988a3ca98e5345d5bc90aa733" title="Defines all possible workloads.">hebench::APIBridge::Workload</a> enumeration. A backend implements a collection of benchmarks and registers them with the Front end during initialization.</p>
<p>The value of field <code>ID</code> is <code>&lt;benchmark_id&gt;</code>. This is an integer number identifying the benchmark to run. These IDs are backend specific that map to a registered benchmark. To obtain the correct ID, users can either find out in the backend documentation, or by exporting the backend default configuration file.</p>
<h3><a class="anchor" id="autotoc_md10"></a>
Workload parameters</h3>
<p>Workloads executed by benchmarks have a number of mandatory parameters. The number and type for these parameters is workload specific. Required parameters for each workload are listed under the <a class="el" href="tests_overview.html">documentation for each workload</a>.</p>
<p>Arguments for the benchmark’s workload parameters are specified under <code>params</code>. This is technically a list of parameters. Each argument is identified by its zero-based index. This index must correspond to the one in the workload documentation. Under its index, an argument specifies a <code>name</code>, a <code>type</code>, and a <code>value</code>.</p>
<p>The value of field <code>name</code> is <code>&lt;param_name&gt;</code>. This is any string used for description purposes. This string can be anything as long as it is unique inside the benchmark section. Names already populated by exported configuration files can be changed, but it is not recommended.</p>
<p>The value of field <code>type</code> is <code>&lt;param_type&gt;</code>. This is a string and must be one of <code>UInt64</code>, <code>Int64</code>, <code>Float64</code>. This is not case sensitive. The correct type for a workload parameter is listed in the corresponding workload documentation.</p>
<p>The <code>value</code> field specifies a range of values for this argument. The sub-fields <code>from</code>, <code>to</code> and <code>step</code> must be numbers compatibles with the type specified by <code>&lt;param_type&gt;</code>. Note that <code>&lt;value_to&gt;</code> must be greater than or equal to <code>&lt;value_from&gt;</code>.</p>
<p>A <code>&lt;value_step&gt;</code> of zero means that only <code>&lt;value_from&gt;</code> will be used in the range.</p>
<p>The range of values for the argument will run as follows:</p>
<div class="fragment"><div class="line"><span class="keywordflow">if</span> (value_step != 0)</div>
<div class="line">{</div>
<div class="line">    <span class="keywordflow">for</span> (value = value_from; value &lt;= value_to; value += value_step)</div>
<div class="line">    {</div>
<div class="line">        <span class="comment">// do something with value</span></div>
<div class="line">    }</div>
<div class="line">}</div>
<div class="line"><span class="keywordflow">else</span></div>
<div class="line">{</div>
<div class="line">    value = value_from;</div>
<div class="line">    <span class="comment">// do something with value</span></div>
<div class="line">}</div>
</div><!-- fragment --><p>For workloads with multiple parameters, all possible combinations for each range will be generated and the benchmark for each combination executed by Test Harness. The order of each combination is undefined.</p>
<p>Finally, backends may have extra workload parameters, beyond those required. Configuration files are expected to fulfill these as well. To know if and which extra parameters a backend has defined for a benchmark, users must consult the specific backend documentation. Exported configuration files may offer a hint at any extra parameters as well.</p>
<h1><a class="anchor" id="autotoc_md11"></a>
Default benchmark configuration</h1>
<p>The best starting point for creating a custom benchmark configuration file is to export the default configuration for a backend.</p>
<p>The exported file will contain the correct information regarding each benchmark ID and its workload parameters. Each benchmark will be preceded by a comment describing what the configuration represents (workload, category, category parameters, etc.).</p>
<p>Users may add, edit or remove benchmarks in this file as needed. Invalid configurations will be rejected by Test Harness when loading.</p>
<p>For example, if a backend exported configuration looks like below:</p>
<div class="fragment"><div class="line">default_min_test_time: 0</div>
<div class="line">default_sample_size: 0</div>
<div class="line">random_seed: 0</div>
<div class="line"> </div>
<div class="line">benchmark:</div>
<div class="line"> </div>
<div class="line"># Benchmark with workload parameters:</div>
<div class="line">#   Logistic Regression PolyD3 16 features</div>
<div class="line"># Descriptor:</div>
<div class="line">#   wp_16 | offline | float64 | 1120 | all_cipher | ckks | 128 | 1</div>
<div class="line">  - ID: 3</div>
<div class="line">    default_min_test_time: 0</div>
<div class="line">    default_sample_size:</div>
<div class="line">      0: 0</div>
<div class="line">      1: 0</div>
<div class="line">      2: 0</div>
<div class="line">    params:</div>
<div class="line">      0:</div>
<div class="line">        name: n</div>
<div class="line">        type: UInt64</div>
<div class="line">        value:</div>
<div class="line">          from: 16</div>
<div class="line">          to: 16</div>
<div class="line">          step: 0</div>
</div><!-- fragment --><p> we know that <code>ID</code> value of <code>3</code> will always represent a "Logistic Regression PolyD3" workload and descriptor "offline | float64 | 1120 | all_cipher | ckks | 128 | 1". The number of features <code>n</code> is the workload parameter <code>0</code> as specified in <a class="el" href="logistic_regression.html">Logistic Regression Inference Workload</a> .</p>
<p>We can modify the parameters at will, as long as our new values are supported by the backend used to export this file.</p>
<p>We can add more benchmarks, as long as their IDs are one of the IDs in the original exported file, and the number of parameters and their types match the correct workload.</p>
<p>Note that adding benchmarks that exactly match parameters of other existing benchmarks will not cause an error. Test Harness will run duplicate benchmarks, but the results of the last run will overwrite the results of any previous runs of the duplicated benchmark.</p>
<h2><a class="anchor" id="autotoc_md12"></a>
Exporting default configuration</h2>
<p>The following command will make Test Harness query the specified backend and generate the file pointed by variable <code>$CONFIG_FILE_PATH</code> containing the benchmark configuration information to run the backend with default parameters, instead of running any benchmarks.</p>
<p>If the file already exists, it will be overwritten without notification.</p>
<div class="fragment"><div class="line">./test_harness --backend_lib_path $BACKEND_LIB --benchmark_config_file $CONFIG_FILE_PATH --dump_config</div>
</div><!-- fragment --><h2><a class="anchor" id="autotoc_md13"></a>
Running with a configuration file</h2>
<p>The command below will launch the Test Harness which will load the file pointed in <code>$CONFIG_FILE_PATH</code>, validate that the selection of benchmarks and parameters are supported by the backend, and then execute only those benchmarks specified in the configuration file.</p>
<div class="fragment"><div class="line">./test_harness --backend_lib_path $BACKEND_LIB --benchmark_config_file $CONFIG_FILE_PATH</div>
</div><!-- fragment --> </div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1 </li>
  </ul>
</div>
</body>
</html>
